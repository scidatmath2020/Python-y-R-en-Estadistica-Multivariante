{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de hipótesis\n",
    "\n",
    "Con frecuencia se desea comprobar si una muestra dada puede provenir de una distribución con ciertos parámetros conocidos.\n",
    "\n",
    "Por ejemplo, en control de calidad se contrasta si el proceso está en estado de control, lo que supone contrastar si las muestras provienen de una población normal con ciertos valores de los parámetros.\n",
    "\n",
    "También puede interesar comprobar si varias muestras multivariantes provienen o no de la misma población. Por ejemplo, comprobar si ciertos mercados son igualmente rentables o si varios medicamentos producen efectos similares.\n",
    "\n",
    "Otro test muy útil es realizar un contraste para ver si la hipótesis de Normalidad no es rechazada por los datos observados, porque estos test de inferencia se basan en la hipótesis de Normalidad de los datos.\n",
    "\n",
    "Es importante saber:\n",
    "* Todo lo que estamos asumiendo sobre nuestros datos.\n",
    "* La información muestral que nos proporcionan los datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de razón de verosimilitudes\n",
    "\n",
    "Para realizar contrastes de hipótesis sobre parámetros vectoriales se suele aplicar el método de razón de verosimilitudes. Esta teoría proporciona pruebas estadísticas con buenas propiedades para tamaños muestrales grandes. Lo cual significa que usualmente se obtienen resultados buenos y fiables.\n",
    "\n",
    "Vamos a asumir que los datos provienen de una población con distribución Normal Multivariante con parámetro vectorial $\\Theta$ y que $\\Theta$ toma valores posibles en un conjunto $\\Omega$, llamado *espacio paramétrico*.\n",
    "\n",
    "Queremos contrastar la hipótesis nula $H_0$ sobre que $\\Theta$ está contenido en una región $\\Omega_0$ del espacio paramétrico, frente a una hipótesis alternativa $H_1$ de que no se encuentra allí:\n",
    "\n",
    "$$\\left\\{\\begin{array}{c}H_0:\\Theta\\in\\Omega_0\\\\H_1:\\Theta\\notin\\Omega_0\\end{array}\\right.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comparar estas dos hipótesis, hay que comparar las probabilidades de obtener los datos bajo ambas hipótesis. El método de razón de verosimilitudes resuelve este problema tomando el valor que hace más probable obtener la muestra observada y que es compatible con la hipótesis.\n",
    "\n",
    "En concreto, la máxima probabilidad de obtener la muestra observada bajo $H_0$ se obtiene como sigue:\n",
    "\n",
    "* Si $\\Omega_0$ determina un valor único para el vector de parámetros (es decir, $\\Omega_0=\\{\\Theta_0\\}$), entonces se calcula la probabilidad de los datos suponiendo $\\Theta=\\Theta_0$.\n",
    "\n",
    "* Si $\\Omega_0$ permite muchos valores, se elige el valor del parámetro que haga máxima la probabilidad de obtener la muestra.\n",
    "\n",
    "Como la probabilidad de la muestra observada es proporcional a la distribución conjunta de las observaciones, al sustituir en esta función los datos, lo que resulta es la función de verosimilitud. Calculando el máximo de esta función en $\\Omega_0$, se obtiene el máximo valor de la verosimilitud compatible con $H_0$ que representaremos por $f(H_0)$. Es decir, $f(H_0)$ es el valor de máximo de la función de verosimilitud cuando la evaluamos en todo el dominio $\\Omega_0$. \n",
    "\n",
    "La máxima probabilidad de obtener la muestra observada bajo $H_1$ se calcula obteniendo el máximo absoluto de la función sobre todo el espacio paramétrico $\\Omega$ (estrictamente debería calcularse en el conjunto $\\Omega-\\Omega_0$, pero es más simple hacerlo sobre todo el espacio ya que en general se obtiene el mismo resultado). Particularizando la función de verosimilitud en su máximo, que corresponde al MLE de los parámetros, se obtiene una cantidad que representaremos como $f(H_1)$. Es decir, $f(H_1)$ es el valor máximo de la función de verosimilitud cuando la evaluamos en todo el dominio $\\Omega$.\n",
    "\n",
    "Sea $RV=\\frac{f(H_0)}{f(H_1)}$ (por construcción $RV\\le1$). **Rechazamos $H_0$ si $RV$ es suficientemente pequeño**. \n",
    "\n",
    "La región de rechazo se define como $RV\\le\\alpha$ donde $\\alpha$ se llama *nivel de significación del test*. Este es determinado a priori por el investigador y se relaciona con *el nivel de confianza* $NC$ como $NC+\\alpha=1$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la práctica, conocer cómo se distribuye $RV$ es difícil (dado que $RV$ depende de $f(H_0)$ y $f(H_1)$, que a su vez dependen de la muestra, de modo que $RV$ puede considerarse por su propio derecho como una variable aleatoria). \n",
    "\n",
    "Sin embargo si llamamos $\\lambda$ a $-2\\log(RV)$, cuando $n$ es grande, tenemos:\n",
    "\n",
    "$$\\lambda=2(L(H_1)-L(H_0))\\sim\\chi^2_m,$$\n",
    "\n",
    "donde el número de grados de libertad $m$ es igual al número de restricciones lineales sobre el vector de parámetros impuestas por $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contraste para la media\n",
    "\n",
    "Consideremos la muestra $x_1,x_2,...,x_n$, tomada de una población $N_p(\\vec{\\mu},\\Sigma)$. Supongamos que queremos contrastar las hipótesis\n",
    "\n",
    "$$\\left\\{\\begin{array}{c}H_0:\\vec{\\mu}=\\vec{\\mu_0}\\\\H_1:\\vec{\\mu}\\neq\\vec{\\mu_0}\\end{array}\\right.$$  Es decir, $\\Omega_0=\\{\\vec{\\mu_0}\\}$. No supondremos nada sobre $\\Sigma$.\n",
    "\n",
    "Dado que conocemos (de la sección C06.1) la función de verosimilitud para $\\vec{\\mu}$, nos resulta que \n",
    "\n",
    "$$L(H_1)=-\\frac{n}{2}\\log|S|-\\frac{np}{2}\\,\\,y\\,\\,L(H_0)=-\\frac{n}{2}\\log|S_0|-\\frac{np}{2},$$\n",
    "\n",
    "donde $S$ es la covarianza muestral y $S_0=\\frac{1}{n}\\sum_{j=1}^n(x_{i\\cdot}-\\vec{\\mu_0})(x_{i\\cdot}-\\vec{\\mu_0})^T.$ \n",
    "\n",
    "Por lo tanto $$\\lambda=n\\log\\left(\\frac{|S_0|}{|S|}\\right).$$\n",
    "\n",
    "Rechazamos $H_0$ si $RV$ es pequeño, lo que significa que $\\lambda$ sea grande. Como $\\lambda\\sim\\chi^2_m$, se puede demostrar que en este caso $m=p$ (el número de características que estamos estudiando).\n",
    "\n",
    "Si $n$ no es grande, se sabe que $\\frac{|S_0|}{|S|}=1+\\frac{T^2}{n-1}$ donde $T^2$ es una *distribución de Hotelling* con $p$ y $n-1$ grados de libertad. En este caso, $T^2=(n-1)(\\overline{x}-\\vec{\\mu_0})^TS^{-1}(\\overline{x}-\\vec{\\mu_0})$.\n",
    "\n",
    "**Observación.** La $T^2$ de Hotelling se relaciona con la F de Fisher de la siguiente manera: $$F_{p,n-p}=\\frac{n-p}{p(n-1)}T^2.$$\n",
    "\n",
    "Por lo tanto $\\lambda=n\\log\\left(1+\\frac{T^2}{n-1}\\right)$ y rechazamos $H_0$ cuando $T^2$ sea grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo.**\n",
    "\n",
    "Un proceso industrial fabrica elementos cuyas características de calidad se miden por un vector de tres variables $X=(X_1,X_2,X_3)$. Cuando el proceso está en estado de control, los valores medios de las variables deben ser $(12,4,2)$. Para comprobar si el proceso funciona adecuadamente, se toma una muestra de $n=20$ elementos y se miden las tres características. \n",
    "\n",
    "Supongamos que hemos obtenido como media muestral a $\\overline{x}=(11.5,4.3,1.2)$ y matriz de covarianzas \n",
    "\n",
    "$$\\Sigma=\\left(\\begin{array}{ccc}10&4&-5\\\\4&12&-3\\\\-5&-3&4\\end{array}\\right).$$\n",
    "\n",
    "¿Estará el proceso en estado de control?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución.**\n",
    "\n",
    "Estar en estado de control significa que la media verdadera del proceso es $(12,4,2)$. Por lo tanto queremos contrastar\n",
    "\n",
    "$$\\left\\{\\begin{array}{c}H_0:\\vec{\\mu}=(12,4,2)\\\\H_1:\\vec{\\mu}\\neq(12,4,2).\\end{array}\\right.$$\n",
    "\n",
    "La información muestral que tenemos es $n=20$ y los valores de  $\\overline{x}$ y $\\Sigma$. Además, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu0 = c(12,4,2)\n",
    "n=20\n",
    "p=3\n",
    "media_muestral = c(11.5,4.3,1.2)\n",
    "S = matrix(c(10,4,-5,4,12,-3,-5,-3,4),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos $T^2$ (recordemos que $T^2=(n-1)(\\overline{x}-\\vec{\\mu_0})^TS^{-1}(\\overline{x}-\\vec{\\mu_0})$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(matlib) # para poder calcular matrices inversas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2 = (n-1)*(media_muestral - mu0) %*% inv(S)  %*% matrix(media_muestral - mu0)\n",
    "T2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos ahora la relación entre la $T^2$ de Hotelling y la F de Fisher: $F_{p,n-p}=\\frac{n-p}{p(n-1)}T^2.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F=(n-p)*T2/(p*(n-1))\n",
    "F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que queremos una significación $\\alpha=0.05$. Entonces queremos hallar $c$ tal que $P(F_{p,n-p}<c)=0.95$. Esta $c$ nos da el umbral: rechazamos $H_0$ si $T^2$ es suficientemente grande; esto significa que rechazamos $H_0$ si $F>c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = qf(0.95,3,17)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observación.** Filosofee un poco sobre la matriz de correlaciones:\n",
    "\n",
    "$$\\left(\\begin{array}{ccc}1&0.37&-0.79\\\\0.37&1&-0.43\\\\-0.79&-0.43&1\\end{array}\\right)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
